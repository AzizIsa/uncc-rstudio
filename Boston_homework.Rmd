---
title: "Boston Housing - Homework"
author: "Aziz Isamedinov"
date: "February 13, 2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Importing Packages
```{r}
library(readr)
library(ggplot2)
library(corrplot)
library(mlbench)
library(reshape2)
library(caret)
library(caTools)
library(sjPlot)
library(sjmisc)
library(car)
```

#Import data from SCVDataset

```{r}
#Reading CSV file 
boston_h=read.csv(file="C:/Users/azizi/Documents/CSVDatasets/Boston_Housing.csv", sep = ",")
```

```{r}
#Attribute Information
str(boston_h)
```
#Descriptive statistics

```{r}
#summarize dataframe
summary(boston_h)
```

Data Exploration

1.a. Check for missing values in the dataset. 

Answer: No missing values are found

```{r}
#Searching NA in the dataframe
which(is.na(boston_h))
```
#1.b. Plot the distribution of MEDV. What do you observe?

Answer:

```{r}
#Plot Histogram
qplot(boston_h$MEDV, geom="histogram", fill=I("seagreen"), binwidth=2)
```

1.c. Generate box-plots of the AGE (proportion of owner-occupied units built prior to 1940) and
MEDV (median home value) attributes and identify the cutoff values for outliers. 



```{r}
#Generate Boxplot from  AGE data
boxplot(boston_h$AGE,col=c("orange"),main="Boxplot of owner-occupied units built prior to 1940")
```

```{r}
#Generate boxplot from  MEDV data
boxplot(boston_h$MEDV,col=c("orange"),main="Median Home Value")
```
#1.d.Generate a scatterplot of MEDV against AGE; comment on how inclusion of the outliers would affect a predictive model of median home value as a function of AGE.

Answer:

```{r}
#Generate Scatter for MEDV vs AGE
plot(boston_h$MEDV, boston_h$AGE, type="p", pch=20, col="blue", lty=3)
```

#2. Try to fit an MLR to this dataset, with MEDV as the dependent variable. MEDV has a somewhat long tail and is not so Gaussian-like, so we will take a log transform, (use LMEDV = log(MEDV)), and then predict LMDEV instead. (You should convince yourself that this is a better idea by looking at the histograms and quantile plots to assess normality; however, no need to submit such plots). Keep the first 356 records as a training set (call it Bostrain) which you will use to fit the model; the remaining 150 will be used as a test set (Bostest). Use only LSTAT, RM, TAX, AGE and ZN as independent (predictor) variables and LMEDV as dependent (target) variable as follows when constructing a linear regression model:

```{r}
#Convert MEDV data to log and split data into two parts
boston_h$LMEDV = log(boston_h$MEDV)
bos_train<-boston_h[1:356,]
bos_test<-boston_h[357:506,]

#Run regression with the given model 
fit1<-lm(LMEDV~LSTAT+RM+TAX+AGE+ZN, data=bos_train)
summary(fit1)
anova(fit1)
```

#3. Do any variables have to be dropped because of multicollinearity?(Use VIF criteria to check for multicollinearity)

Answer: 

#4.Report the coefficients obtained by your model. Would you drop any of the variables used in your model (based on the t-scores or p-values)?

Answer:

```{r}
# viffunction to check wether multicollinearity exists amoung  variables
vif(fit1)
```

#5.Rerun your regression model after removing variables (if any) based on your analysis in the previous question. What is the value of R2 ? What does it signify? #What is the overall F-statistic and the corresponding p-value of this final model? What does it signify?

Answer: 

#6. What is the overall F-statistic and the corresponding p-value of this final model? What does it signify?

Answer:
```{r}
#Regression analysis after removing variables
fit2= lm(LMEDV~LSTAT+RM+TAX+AGE, data=bos_train)
summary(fit2)
```




#7. Report the MSE obtained on Bostrain. How much does this increase when you score your model (i.e.,predict) on Bostest?

Answer:

```{r}
#Find MSE for the bos train
MSE_bostrain=mean(fit1$residuals^2)
MSE_bostrain

# model to predict MSE for bostest
test_predict = predict(fit1, bos_test)
MSE_bostest= mean((bos_test$LMEDV-test_predict)^2)
MSE_bostest
```

#(Bonus 1 point). Use the stepwise regression considering to reach your final model (LMEDV as dependent variable and all but MEDV as independent variables). Try different model section criteria (i.e., AIC, Cp, BIC, adj R^2) and see if you can come up with the same model even with the different criteria. Determine the best model if you get different models with different criteria? We will consider a model that gives the highest accuracy (in terms of MSE) in the test set as the best model.

Answer:

```{r}

#Determine the best model
step(lm(LMEDV~.-MEDV,data=bos_train))

#Using the 1st model calculate MSE
fit3=lm(LMEDV ~ (CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +TAX + PTRATIO + B + LSTAT + MEDV) - MEDV, data=bos_train)
fit3_predict = predict(fit3, bos_train)
mse_fit3 = mean(bos_train$LMEDV-fit3_predict)^2

#Using the 2st model calculate MSE
fit4=lm(LMEDV ~ ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT, data= bos_train)
fit4_predict = predict(fit4, bos_train)
mse_fit4 = mean(bos_train$LMEDV-fit4_predict)^2

#Print out all models MSE
mse_fit3
mse_fit4
```









